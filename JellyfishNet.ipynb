{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JellyfishNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOvOw6hIHVcW6Z8jOvND4L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krzs13/JellyfishNet/blob/master/JellyfishNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7nydSWUCprb",
        "colab_type": "text"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "\n",
        "0. Dependencies\n",
        "1. Introduction\n",
        "2. Data Preparation\n",
        "    * 2.1 Load Data\n",
        "    * 2.2 Data Normalization\n",
        "    * 2.3 Train/Validation Set Split\n",
        "    * 2.4 Data Augmentation\n",
        "3. JellyfishNet\n",
        "    * 3.1 Main Assumption\n",
        "    * 3.2 Architectural Highlights\n",
        "    * 3.3 Model\n",
        "4. Hyperparameters Tuning\n",
        "    * 4.1 Keras Tuner\n",
        "    * 4.2 Regularization Layers\n",
        "    * 4.3 Activation Layers\n",
        "    * 4.4 Dense Units\n",
        "    * 4.5 Data Augmentation Parameters\n",
        "    * 4.6 Learning Rate and Learning Rate Reduction\n",
        "5. Model Evaluation\n",
        "    * 5.1 TensorBoard\n",
        "6. Prediction and Model Ensemble\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipid1Qr0G7cI",
        "colab_type": "text"
      },
      "source": [
        "# 0. Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZFpnGgX5jDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import os\n",
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hTAP-unJ9fY",
        "colab_type": "text"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "**99,75% of test accuracy and only 234 330 trainable parameters!**\n",
        "\n",
        "The moment I learned about attention in machine learning, I wanted to create my model that used this concept. I found attention helpful for the model to focus on the essentials, which would allow for a simple solution. All of that was the reason why JellyfishNet was created - to make as simple model as possible that would use concept of attention and have small amount of trainable parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-pmAWLR5uKB",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data Preperation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB3UnsUN506H",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Load Data\n",
        "\n",
        "For this task I am using original MNIST dataset, so training set contains 60 000 images and 10 000 images are for test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e55NoS4954I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYPRGRNc-UAm",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Data Normalization\n",
        "\n",
        "MNIST dataset contains images in grayscale with pixel values from 0 to 255 stored as 2D NumPy arrays. TensorFlow operates on tensors which are 3D arrays so I am adding another dimension called 'channel' by expand_dims method from NumPy package. Convolutional Neural Networks converge faster on smaller values from 0-1 range then 0-255 range so pixel values are divided by 255 and stored as float32 data type. Train labels which are integer numbers are encoded to one hot array so label with category of 2 is [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]. I also make sure that labels are same data type int8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS3Avc0P-Zbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = (np.expand_dims(train_images, axis=-1) / 255).astype(np.float32)\n",
        "train_labels = tf.keras.utils.to_categorical(\n",
        "    train_labels, num_classes=10, dtype=np.int8)\n",
        "\n",
        "test_images = (np.expand_dims(test_images, axis=-1) / 255).astype(np.float32)\n",
        "test_labels = (test_labels).astype(np.int8)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou5qWKU5GUEO",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Train/Validation Set Split\n",
        "\n",
        "Training set is split into training and validation sets by train_test_split method from scikit-learn package. Validation set contains 10% images of original training set. Stratify parameter in train_test_split method means that train and vaidation sets have same proportions of class labels which is important for proper learning of model. Random state is set to value 42 (popular random seed) to make sure that split is always the same over different runs so results are more reliable and models could be compared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj7sFT8uG7L2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    test_size=0.1, \n",
        "    random_state=42, \n",
        "    stratify=train_labels,\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b6s4o6yG9sP",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Data Augmentation\n",
        "\n",
        "Data augmentation is used to prevent overfitting. The idea is to alter the training data with small transformations so neural network 'sees' more images while learning. \n",
        "* rotation_range - randomly applies rotation to images. Small amount is chosen to avoid confiusion between 6 and 9\n",
        "* zoom_range - randomly applies zoom to images\n",
        "* width_shift_range - randomly shift images horizontally\n",
        "* height_shift_range - randomly shift images vertically\n",
        "\n",
        "ImageDataGenerator contains other methods of image augmentation, but I didn't find them usefull for MNIST dataset because they don't make model learn better.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN3eVnI7Gtje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(  \n",
        "    rotation_range=10,  \n",
        "    zoom_range=0.2, \n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2,\n",
        ")\n",
        "\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_I9laTWjFrt",
        "colab_type": "text"
      },
      "source": [
        "# 3. JellyfishNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcc9D72ujOPt",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Main Assumption\n",
        "\n",
        "The goal of JellyfishNet was to create simple model with attention that has low amount of trainable parameters and don't need much computational power. I assumed that using just convolution with softmax activation that is multiplied with convolution with non linear activation in first layers of network will be good enough for as simple task as digit recognition. Gaussian Noise was chosen as regularization for head layers and Gaussian Dropout was chosen for spine and fully connected layers. The idea was to use regularization after each block with small rate amount instead regularization after several bocks with bigger rate amount as is usually seen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLRw41BanjWM",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Architectural Highlights\n",
        "\n",
        "JellyfishNet is made of two heads with simple attention modules that are connected to spine made of convolutional blocks. Last block of network is fully connected layer.\n",
        "\n",
        "* Head contains two blocks. Each block contains two strided convolutions with kernel size equal to 3 and 7. Convolution with smaller kernel size has ReLU activation layer and one with bigger kernel size has Softmax activation. Each block has own Gaussian Noise and Batch Normalization layers. At last outputs of ReLU and Softmax are multiplied. \n",
        "\n",
        "* Heads are concatenated. Before concatenation head with lower stride amount is passed through convolution to make it having same amount and size of filters. This convolution layer has same regularization and activation layers as spine.\n",
        "\n",
        "* Spine contains three blocks with convolutions that lower amount of filters from 128 to 16. Convolutions have stride amount of 1 so filters size is constant from the beginning to the end of spine. Each block contains own Gaussian Dropout and Batch Normalization. Swish activation was chosen in hyperparameters tuning process.\n",
        "\n",
        "* Fully connected part of JellyfishNet begins from Flatten layer. Resized output is passed through just one Dense layer to have smaller amount of trainable parameters. Dense block has own Guassian Dropout and Batch Normalization. LeakyReLU activation was chosen in hyperparameters tuning process. Last layer is standard classification with Dense layer and Softmax activation.\n",
        "\n",
        "* Model plot (my lovely girlfriend told me it looks like jellyfish and that's why it's called like that ðŸ˜‰): ![JellyfishNet](https://drive.google.com/uc?export=view&id=1oBEaipwtevLA5fivWHiYMV-nPhdWorBx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROjKjG4qM1v2",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJBtbHGJq__7",
        "colab_type": "text"
      },
      "source": [
        "### Head Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aWxiFWuM4sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HeadLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        filters: int, \n",
        "        strides: Tuple[int, int], \n",
        "        gaussian_noise_ratio: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._conv = tf.keras.layers.Conv2D(\n",
        "            filters,\n",
        "            3,\n",
        "            strides=strides,\n",
        "            padding='same',\n",
        "        )\n",
        "        self._conv_noise = tf.keras.layers.GaussianNoise(gaussian_noise_ratio)\n",
        "        self._conv_activation = tf.keras.layers.Activation(tf.nn.relu)\n",
        "        self._conv_batchnorm = tf.keras.layers.BatchNormalization()\n",
        "        self._soft = tf.keras.layers.Conv2D(\n",
        "            filters,\n",
        "            7,\n",
        "            strides=strides,\n",
        "            padding='same',\n",
        "        )\n",
        "        self._soft_noise = tf.keras.layers.GaussianNoise(gaussian_noise_ratio)\n",
        "        self._soft_activation = tf.keras.layers.Softmax()\n",
        "        self._soft_batchnorm = tf.keras.layers.BatchNormalization()\n",
        "        self._multiply = tf.keras.layers.Multiply()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        conv = self._conv(inputs)\n",
        "        conv = self._conv_noise(conv)\n",
        "        conv = self._conv_activation(conv)\n",
        "        conv = self._conv_batchnorm(conv)\n",
        "\n",
        "        soft = self._soft(inputs)\n",
        "        soft = self._soft_noise(soft)\n",
        "        soft = self._soft_activation(soft)\n",
        "        soft = self._soft_batchnorm(soft)\n",
        "\n",
        "        multiply = self._multiply([conv, soft])\n",
        "\n",
        "        return multiply"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cGgvxYXwBgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HeadConvolutionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        filters: int,\n",
        "        strides: Tuple[int, int],  \n",
        "        gaussian_dropout_ratio: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._conv = tf.keras.layers.Conv2D(\n",
        "            filters,\n",
        "            3,\n",
        "            strides=strides,\n",
        "            padding='same',\n",
        "        )\n",
        "        self._dropout = tf.keras.layers.GaussianDropout(gaussian_dropout_ratio)\n",
        "        self._activation = tf.keras.layers.Activation(tf.nn.swish)\n",
        "        self._batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self._conv(inputs)\n",
        "        x = self._dropout(x)\n",
        "        x = self._activation(x)\n",
        "        x = self._batchnorm(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0p588QNuBvA",
        "colab_type": "text"
      },
      "source": [
        "### Spine Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBBU4w-juA46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SpineLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        filters: int, \n",
        "        gaussian_dropout_ratio: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._conv = tf.keras.layers.Conv2D(\n",
        "            filters,\n",
        "            3,\n",
        "            strides=(1, 1),\n",
        "            padding='same',\n",
        "        )\n",
        "        self._dropout = tf.keras.layers.GaussianDropout(gaussian_dropout_ratio)\n",
        "        self._activation = tf.keras.layers.Activation(tf.nn.swish)\n",
        "        self._batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self._conv(inputs)\n",
        "        x = self._dropout(x)\n",
        "        x = self._activation(x)\n",
        "        x = self._batchnorm(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdIAYwN8uu9_",
        "colab_type": "text"
      },
      "source": [
        "### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aoIKbq9uuUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FullyConnectedLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        units: int, \n",
        "        gaussian_dropout_ratio: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._flatten = tf.keras.layers.Flatten()\n",
        "        self._dense = tf.keras.layers.Dense(units)\n",
        "        self._dropout = tf.keras.layers.GaussianDropout(gaussian_dropout_ratio)\n",
        "        self._activation = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "        self._batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self._flatten(inputs)\n",
        "        x = self._dense(x)\n",
        "        x = self._dropout(x)\n",
        "        x = self._activation(x)\n",
        "        x = self._batchnorm(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCBaAUTtwsr6",
        "colab_type": "text"
      },
      "source": [
        "### JellyfishNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwDLArfFwrwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JellyfishNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._head_1 = HeadLayer(\n",
        "            filters=64, strides=(4, 4), gaussian_noise_ratio=0.02)\n",
        "        self._head_2 = HeadLayer(\n",
        "            filters=128, strides=(2, 2), gaussian_noise_ratio=0.02)\n",
        "        self._head_2_conv = HeadConvolutionLayer(\n",
        "            filters=64, strides=(2, 2), gaussian_dropout_ratio=0.07)\n",
        "        self._concatenate = tf.keras.layers.Concatenate()\n",
        "        self._spine_1 = SpineLayer(filters=64, gaussian_dropout_ratio=0.07)\n",
        "        self._spine_2 = SpineLayer(filters=32, gaussian_dropout_ratio=0.07)\n",
        "        self._spine_3 = SpineLayer(filters=16, gaussian_dropout_ratio=0.07)\n",
        "        self._fully_connected = FullyConnectedLayer(\n",
        "            units=64, gaussian_dropout_ratio=0.07)\n",
        "        self._classification = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        head_1 = self._head_1(inputs)\n",
        "        head_2 = self._head_2(inputs)\n",
        "        head_2 = self._head_2_conv(head_2)\n",
        "        concatenate = self._concatenate([head_1, head_2])\n",
        "\n",
        "        spine = self._spine_1(concatenate)\n",
        "        spine = self._spine_2(spine)\n",
        "        spine = self._spine_3(spine)\n",
        "\n",
        "        fully_connected = self._fully_connected(spine)\n",
        "\n",
        "        classification = self._classification(fully_connected)\n",
        "\n",
        "        return classification"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QyrUZ99M5uQ",
        "colab_type": "text"
      },
      "source": [
        "# 4. Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GokCiudANIkT",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Keras Tuner\n",
        "\n",
        "Keras Tuner is amazing package that makes hyperparameter tuning pretty easy. For JellyfishNet I used Hyperband method which is optimized Random Search. Hyperband works simmilar to genetic alghoritms so at the start it makes many networks with different parameters and the best half of them  get to the next round. The algorithm is repeated until there is one best network left. This section doesn't contain code because whole process of hyperparameters tuning took about 9 hours at single V100 GPU instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGe_H-e0PpAv",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Regularization Layers\n",
        "\n",
        "Type of regularization layers were chosen by hand (Guassian Noise for heads and Gaussian Dropout for rest of the JellyfishNet) but their rates were chosen by Keras Tuner. Range given to Keras Tuner was from 0.01 to 0.10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPBxRmawQUrJ",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Activation Layers\n",
        "\n",
        "The only activation layers chosen by hand where Softmax at head and clasification layer. Keras Tuner did his job for rest of the network. It could choose between ReLU, LeakyReLU and Swish activations. Because of using activations from tf.nn package alpha amount at LeakyReLU is 0.2 which is default alpha amount for tf.nn.leaky_relu instead of default amount for tf.keras.layers.LeakyReLU which is 0.3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZezdF4_21h5W",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Dense Units\n",
        "\n",
        "Amount of units in Dense layer from fully connected block was chosen by Keras Tuner. Choices were from range from 32 to 192 with step of 16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi8VYaBGRhbN",
        "colab_type": "text"
      },
      "source": [
        "## 4.5 Data Augmentation Parameters\n",
        "\n",
        "Data augmentation parameters were chosen by hand. I found out that bigger amount of data augmentation rates results with worse single model performance but better model ensemble result. I decided not to use Keras Tuner here because it choose best parameters only for single model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM1YsGsUShJE",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 Learning Rate and Learning Rate Reduction\n",
        "\n",
        "These parameters were also chosen by hand and by looking at accuracy/loss model performance plots. I choosed ReduceLROnPlateu method from tf.keras.callbacks package. This method reduces learning rate by chosen factor when network stops performing better. Patience parameter was chosen according to my observations at JellyfishNet habits. There is also early stopping callback to stop learning process after 7 epochs without progress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXbmWVi625Ux",
        "colab_type": "text"
      },
      "source": [
        "# 5. Model Evaluation\n",
        "\n",
        "This model learns pretty well because the validation accuracy is greater than the training accuracy every time during training session. That means that JellyfishNet doesn't overfit the training set.\n",
        "\n",
        "![Accuracy](https://drive.google.com/uc?export=view&id=1fjI01d5PuydANg1kABxxfa93KMKN07ty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTtPBbeREdR0",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMDkOReEWAoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p logs\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NiJH7YA3Fa2",
        "colab_type": "text"
      },
      "source": [
        "# 6. Prediction and Model Ensemble\n",
        "\n",
        "Model learns well with batch size of 50 and initial learning rate of 0.001. Max amout of epochs doesn't matter because of early stopping after 7 epochs while network doesn't make any progress. There is also model check point callback that saves model according to best validation accuracy. Final submission is made of 15 models ensemble. Average of all predictions is calculated to produce more reliable result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pudidz9U3VGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fef61337-51b7-4121-e3ce-c24f6eccab69"
      },
      "source": [
        "!mkdir -p models\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "MAX_EPOCHS = 200\n",
        "AMOUNT_OF_MODELS_TO_EVALUATE = 15\n",
        "\n",
        "def train_model(batch_size: int, max_epochs: int, amount_of_models_to_evaluate):\n",
        "    ensemble_models = []\n",
        "\n",
        "    for i in range(1, amount_of_models_to_evaluate + 1):\n",
        "        print(f'STEP: {i}/{amount_of_models_to_evaluate}\\n')\n",
        "\n",
        "        model = JellyfishNet()\n",
        "\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_accuracy', patience=7)\n",
        "        learning_rate_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_accuracy', \n",
        "            patience=2, \n",
        "            verbose=1, \n",
        "            factor=0.5, \n",
        "            min_lr=1e-10,\n",
        "        )\n",
        "        model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "            f'models/jellyfishnet_step_{str(i).zfill(3)}',\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1,\n",
        "            save_best_only=True, \n",
        "            save_weights_only=True,\n",
        "        )\n",
        "        log_dir = f'logs/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "            log_dir=log_dir, histogram_freq=1, write_graph=False)\n",
        "        callbacks = [\n",
        "            early_stopping, \n",
        "            learning_rate_scheduler,\n",
        "            model_checkpoint,\n",
        "            tensorboard_callback,\n",
        "        ]\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'],\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
        "            steps_per_epoch=len(train_images) / batch_size,\n",
        "            epochs=max_epochs, \n",
        "            validation_data=(val_images, val_labels), \n",
        "            callbacks=callbacks,\n",
        "        )\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "    for i in range(1, amount_of_models_to_evaluate + 1):\n",
        "        model = JellyfishNet()\n",
        "        model.load_weights(f'models/jellyfishnet_step_{str(i).zfill(3)}')\n",
        "        ensemble_models.append(model)\n",
        "\n",
        "    predictions = [model.predict(test_images) for model in ensemble_models]\n",
        "    predictions = np.array(predictions)\n",
        "    predictions = np.mean(predictions, axis=0)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    accuracy = tf.keras.metrics.Accuracy()\n",
        "    accuracy.update_state(test_labels, predictions)\n",
        "    accuracy = accuracy.result().numpy()\n",
        "\n",
        "    return f'Ensemble accuracy: {str(accuracy * 100)[:7]}%'\n",
        "\n",
        "train_model(BATCH_SIZE, MAX_EPOCHS, AMOUNT_OF_MODELS_TO_EVALUATE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ensemble accuracy: 99.7500%'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}